# -*- coding: utf-8 -*-
"""rekomendasi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10_9rkA3A4fhcnQ-WYa74R-wUr-Uuuhw3

## Import Library

1. import pandas as pd adalah library utama untuk memproses data berbentuk tabel (DataFrame).
2. import matplotlib.pyplot as plt digunakan untuk membuat visualisasi.
3. import seaborn as sns untuk visualisasi statistik yang lebih menarik dan mudah digunakan.
4. import ast digunakan untuk mengubah string literal Python (misalnya string yang berisi list/dictionary) menjadi objek Python.
5. from wordcloud import WordCloud untuk membuat visualisasi berbentuk cloud dari kata-kata paling sering muncul dalam teks.
6. from sklearn.metrics.pairwise import linear_kernel ntuk menghitung kemiripan antar-vektor (misalnya antar film berdasarkan overview) dengan pendekatan dot product / cosine similarity.
7. from sklearn.feature_extraction.text import TfidfVectorizer untuk mengubah kumpulan teks (misalnya overview/tagline film) menjadi vektor numerik berbasis TF-IDF.
8. from collections import Counter untuk menghitung frekuensi elemen dalam list.
9. from sklearn.metrics import confusion_matrix, precision_score, recall_score untuk evaluasi performa sistem klasifikasi/rekomendasi.
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import ast
from wordcloud import WordCloud
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel
from collections import Counter
from sklearn.metrics import confusion_matrix, precision_score, recall_score

"""## Data loading

Menggunakan pd.read_csv untuk membaca database
"""

movies_df = pd.read_csv('Dataset_movie/movies_metadata.csv')
credits_df = pd.read_csv('Dataset_movie/credits.csv')

"""Insight : Melakukan load data kedalam dataframe movies_df dan credits_df.

## Data Understanding

Pada tahap ini dilakukan berbagai tahap untuk memahami struktur, tipe data, dan informasi dasar dari dataset.
"""

movies_df.head()

movies_df.info()

movies_df.shape

movies_df.isnull().sum()

credits_df.head()

credits_df.info()

credits_df.shape

credits_df.isnull().sum()

"""Insight :

1. DataFrame movies_df terdiri dari 45466 baris dan 24 kolom. Dari informasi yang didapatkan kolom genres dan overview dapat digunakan untuk fitur rekomendasi. Kolom id berupa string untuk digabung dengan credits_df.
2. DataFrame credits_df terdiri dari 45476 baris dan 24 kolom. Dari informasi yang didapatkan kolom casr dapat digunakan untuk fitur rekomendasi.Terdapat pula kolom id yang digunakan untuk pengabungan dengan movies_df.
3. Kolom id yang terdapat dalam movies_df masih berupa str perlu di konfersi menjasi int untuk dapat digunakan.
4. Dalam movies_df kolom genres masih dalam format JSON string perlu parsing dengan ast.literal_eval.
5. Dalam movies_df kolom overview masih terdapat nilai null.
6. Dalam cast_df kolom cast masih dalam format JSON string perlu parsing dengan ast.literal_eval.

## EDA

Dilakukan analisis awal terhadap data untuk menentukan pola, anomali, dan insight manarik. Karena dari data understanding kita telah melakukan pemilihan fitur untuk model rekomendasi oleh karenanya dalam kolom genres dan cast perlu dilakukan parsing untuk melihat visualisasinya.
"""

movies_df.describe()

"""Melakukan parse 'genres' string menjadi list of dict dengan ast.literal_eval kemudian menyimpan nya dalam dataframe genre_exploded. Lalu dari genre_exploded dilakuakan perhitungan tiap genre karena fitur genres berisi multiple genres per film dengan .value_counts()"""

movies_df['genres'] = movies_df['genres'].fillna('[]').apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else [])
movies_df['genres'] = movies_df['genres'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])
genre_exploded = movies_df.explode('genres')
genre_counts = genre_exploded['genres'].value_counts()

"""Visualisasi Genre"""

plt.figure(figsize=(12,6))
sns.barplot(x=genre_counts.values, y=genre_counts.index, palette='viridis')
plt.title('Distribusi Genre Film')
plt.xlabel('Jumlah Film')
plt.ylabel('Genre')
plt.tight_layout()
plt.show()

"""Insight:

Genre yang paling banyak diproduksi adalah Drama, diikuti oleh Comedy, Thriller, dan Romance. Beberapa genre niche seperti Western, War, dan TV Movie hanya memiliki sedikit film. Terdapat label produksi seperti Carousel Productions dalam genre ini bisa jadi kesalahan parsing atau duplikasi kolom saat explode, jadi perlu dibersihkan.
"""

movies_df['overview'] = movies_df['overview'].fillna('')
movies_df['overview_len'] = movies_df['overview'].apply(lambda x: len(x.split()))

plt.figure(figsize=(10,6))
sns.histplot(movies_df['overview_len'], bins=50, kde=True)
plt.title('Distribusi Panjang Overview (dalam jumlah kata)')
plt.xlabel('Jumlah Kata')
plt.ylabel('Jumlah Film')
plt.show()

"""Insight:

Sebagian besar overview memiliki panjang sekitar 20–40 kata, yang menunjukkan bahwa mayoritas sinopsis film cukup pendek. Terdapat ekor panjang ke kanan (right-skewed), menandakan adanya overview dengan kata yang sangat banyak (hingga >150).
"""

text = ' '.join(movies_df['overview'])
wordcloud = WordCloud(width=1000, height=500, background_color='white', stopwords='english').generate(text)

plt.figure(figsize=(15,7))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('WordCloud Overview Film')
plt.show()

"""Insight:

Kata-kata yang dominan adalah kata umum dalam bahasa Inggris seperti: "the", "a", "to", "of", "in", dll. Kata kunci kontekstual yang cukup sering muncul: "young", "man", "finds", "story", "life", "family" → menunjukkan tema film umum. Perlu melakukan stopwords removal.

Melakukan parse pada dataframe credits_df kolom cast dengan mengunakan ast.literal_eval(). Dari list cast hanya diambil 3 nama pertama kemudian akan disimpan di kolom baru bernama 'main_cast'.
"""

credits_df['cast'] = credits_df['cast'].apply(ast.literal_eval)
credits_df['main_cast'] = credits_df['cast'].apply(lambda x: [i['name'] for i in x[:3]])
exploded_cast = credits_df.explode('main_cast')
top_actors = exploded_cast['main_cast'].value_counts().head(10)
print(top_actors)

plt.figure(figsize=(10,6))
sns.barplot(y=top_actors.index, x=top_actors.values, palette='magma')
plt.title('10 Aktor yang Paling Sering Muncul')
plt.xlabel('Jumlah Film')
plt.ylabel('Aktor')
plt.show()

"""Insight:

Aktor-aktor ini menunjukkan produktivitas tinggi dalam jangka waktu panjang, tidak hanya dari satu dekade atau genre saja. Dominasi Gender: Hanya 1 wanita (Bette Davis) dalam 10 besar, mengindikasikan kemungkinan ketimpangan peran utama antara aktor dan aktris dalam industri film pada masa lalu. Keberagaman Asal: Terdapat aktor dari berbagai latar belakang budaya: Amerika (John Wayne, Jackson), Eropa (Depardieu, Mason), Asia (Jackie Chan), menunjukkan jangkauan global industri film.

## Data Preparation

Pada langkah ini melakukan persipan data bersarkan insight yang telah di dapatkan pada data understanding dan EDA.

Melakukan pembersihan data pada kolom 'overview' karena merupakan salah satu fitur yang digunakan pada pemodelan.
"""

movies_df['overview'] = movies_df['overview'].fillna('')

"""Mengubah type data pada kolom id yang sebelumnya masih bertype object diubah menjadi int."""

movies_df['id'] = pd.to_numeric(movies_df['id'], errors='coerce')
movies_df = movies_df.dropna(subset=['id'])
movies_df['id'] = movies_df['id'].astype(int)

"""Insight :

Penanganan label tidak relevan pada kolom genres terjadi karena data korup, kemungkinan karena baris-baris tersebut berasal dari entri dengan `id` yang tidak valid.  Baris-baris tersebut telah dihapus saat proses konversi `id` ke integer.

Melakukan pengececekan terkait perubahan di atas.
"""

movies_df.isnull().sum()

unique_genres = set([genre for sublist in movies_df['genres'] for genre in sublist])

print("Daftar Genre Unik:")
for genre in sorted(unique_genres):
    print(genre)

"""Langkah selanjutnya adalah menggabungkan kedua DataFrame, yaitu movies_df dan credits_df, berdasarkan kolom id."""

credits_df['id'] = credits_df['id'].astype(int)
movies_df['id'] = movies_df['id'].astype(int)
credits_clean = credits_df[['id', 'main_cast']]
df = movies_df.merge(credits_clean, on='id')

"""Mengurutkan df berdasarkan id terkecil"""

df = df.sort_values('id').reset_index(drop=True)

df.head()

"""Dataset film yang digunakan awalnya memiliki ukuran yang sangat besar, sehingga pengolahan data secara penuh berpotensi menyebabkan keterbatasan memori dan waktu komputasi yang signifikan, terutama pada tahap perhitungan matriks kemiripan (cosine similarity) yang memerlukan sumber daya besar.
Untuk mengatasi kendala ini, dilakukan pemilihan subset data dengan mengambil 20.000 baris pertama dari dataset utama.
"""

df_subset = df.head(20000).copy()

"""Menggabungkan genres, overview, dan main_cast ke dalam satu kolom teks gabungan (soup), sebagai dasar content-based filtering."""

def clean_data(x):
    if isinstance(x, list):
        return ' '.join(x)
    elif isinstance(x, str):
        return x
    else:
        return ''

df_subset['soup'] = df_subset['genres'].apply(clean_data) + ' ' + \
                    df_subset['main_cast'].apply(clean_data) + ' ' + \
                    df_subset['overview']

"""Pada tahap ini, data teks yang sudah dipersiapkan (fitur gabungan seperti genre, cast, dan overview yang digabung menjadi satu kolom "soup") diubah menjadi representasi numerik menggunakan metode TF-IDF.TF-IDF vectorizer diatur dengan parameter stop words bahasa Inggris untuk menghilangkan kata-kata umum yang kurang bermakna (misalnya: "the", "and", "is")."""

tfidf = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf.fit_transform(df_subset['soup'])
print("TF-IDF matrix shape:", tfidf_matrix.shape)

"""Melihat 10 fitur pertama dari TF-IDF vocabulary."""

feature_names = tfidf.get_feature_names_out()
print("Contoh fitur TF-IDF:", feature_names[:10])

"""Menampilkan sebagian nilai TF-IDF untuk 5 film pertama dan 10 kata pertama."""

sample_tfidf = tfidf_matrix[:5, :10].toarray()

print(sample_tfidf)

"""## Modeling

Implementasi cosine similarity dilakukan dengan menggunakan fungsi linear_kernel dari pustaka scikit-learn. Fungsi ini menghitung dot product antar vektor TF-IDF, yang dalam konteks vektor sudah ternormalisasi sama dengan cosine similarity.
"""

cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)
print("Cosine similarity matrix shape:", cosine_sim.shape)
print("Similarity film index 0 dengan film lain:", cosine_sim[0][:10])

"""Kode ini digunakan untuk mencari 10 film yang paling mirip dengan sebuah film tertentu berdasarkan nilai cosine similarity. Nilai kemiripan ini dihitung dari representasi teks gabungan yang terdiri dari fitur genres, overview, dan cast menggunakan metode TF-IDF (Term Frequency-Inverse Document Frequency)."""

index_film = 0
sim_scores = list(enumerate(cosine_sim[index_film]))

sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
top_similar = sim_scores[1:11]  # Ambil 10 teratas

for i, score in top_similar:
    print(f"{movies_df['title'][i]} (Similarity Score: {score:.4f})")

"""## Mendapatkan Rekomendasi

Setelah membangun matriks cosine similarity, kita dapat memanfaatkannya untuk membangun sistem rekomendasi yang mampu memberikan daftar film yang paling mirip dengan film tertentu. Pada bagian ini, kita membangun fungsi rekomendasi berdasarkan judul film input dari pengguna.

Fungsi get_recommendations()

Fungsi ini dirancang untuk menerima input berupa judul film, lalu mengembalikan 10 film paling mirip berdasarkan nilai cosine similarity.
"""

movies_df = movies_df.reset_index(drop=True)
indices = pd.Series(movies_df.index, index=movies_df['title'].str.lower())

def get_recommendations(title, cosine_sim=cosine_sim):
    title = title.lower()
    idx = indices.get(title)

    if idx is None:
        return "Judul tidak ditemukan dalam dataset."

    # Jika idx adalah array-like, ambil indeks pertama
    if isinstance(idx, pd.Series):
        idx = idx.iloc[0]

    sim_scores = list(enumerate(cosine_sim[idx]))

    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:11]  # exclude itself

    movie_indices = [i[0] for i in sim_scores]

    return movies_df[['title', 'genres']].iloc[movie_indices]

"""Contoh Penggunaan"""

get_recommendations("The Dark Knight Rises")

"""## Evaluasi

Untuk mengevaluasi performa sistem rekomendasi secara kualitatif, dilakukan evaluasi manual dengan memilih beberapa judul film populer sebagai test case. Film yang dipilih diharapkan memiliki karakteristik yang kuat, sehingga memungkinkan untuk melihat apakah sistem mampu menghasilkan rekomendasi yang relevan secara tematis maupun berdasarkan kemiripan fitur.
"""

titles_to_test = ["The Dark Knight", "The Dark Knight Rises",]

for title in titles_to_test:
    print(f"Rekomendasi untuk film: {title}")
    print(get_recommendations(title))
    print('-'*100)

def plot_genre_distribution(recommendations):
    # Flatten list of genres
    all_genres = []
    for genres_list in recommendations['genres']:
        if isinstance(genres_list, list):
            all_genres.extend(genres_list)
        else:
            all_genres.append(genres_list)

    genre_counts = Counter(all_genres)
    genres, counts = zip(*genre_counts.most_common())

    plt.figure(figsize=(10,6))
    plt.bar(genres, counts)
    plt.xticks(rotation=45, ha='right')
    plt.title('Distribusi Genre Film Rekomendasi')
    plt.xlabel('Genre')
    plt.ylabel('Jumlah')
    plt.show()

recommendations = get_recommendations("The Dark Knight")
plot_genre_distribution(recommendations)

recommendations = get_recommendations("The Dark Knight Rises")
plot_genre_distribution(recommendations)

"""Selain evaluasi manual, dilakukan juga evaluasi kuantitatif untuk menilai sejauh mana sistem rekomendasi mampu menyarankan film yang benar-benar relevan bagi pengguna. Pada tahap ini, metrik evaluasi yang digunakan meliputi:
1. Confusion Matrix
2. Precision
3. Recall
"""

ground_truth = set(["The Dark Knight", "Inception", "Interstellar"])

recommendations = set(["Justice League", "Inception", "The Dark Knight", "Avatar"])

all_films = list(set(movies_df['title'].tolist()))

y_true = [1 if film in ground_truth else 0 for film in all_films]
y_pred = [1 if film in recommendations else 0 for film in all_films]

cm = confusion_matrix(y_true, y_pred)

print("Confusion Matrix:")
print(cm)

precision = precision_score(y_true, y_pred)
recall = recall_score(y_true, y_pred)

print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")

plt.figure(figsize=(6,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Not Recommended', 'Recommended'],
            yticklabels=['Not Relevant', 'Relevant'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()